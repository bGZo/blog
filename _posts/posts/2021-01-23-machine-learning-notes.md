---
layout: post
title: Machine Learning Notes
updated: 2021-01-22
category: posts
---

机器学习最重要的是“预测”，因此“机器学习”包含两个部分:
- **训练**：比如提供大量的汽车图片给机器“学习”，教会机器什么是车，这就是训练
- **预测**：训练结束后，我们需要机器可以对没有见过的图片进行判断，并且要保证一定的正确率，这就是预测

机器学习适用于：
- 要解决的问题中存在**某种模式**
- 这种模式**不容易直接定义**
- 有**足够的数据**可以帮助我们找出该模式

<!--more-->

## 分类

如下<sup>[1](#j1)</sup>: 

- **监督式学习**
    - 手写识别
- **无监督学习**
    - 每日推荐
- **强化学习**
    - AlphaGo
- **深度学习**



## 感知机

- **感知机:** 对神经元 (neuron) 的简单抽象 
    - 通过该历史数据训练之后，就可以判断某件事情
    - 分界线总是直线, 属于**线性分类模型**的一种
    - 感知机是分类中最简单的算法，实用性并不高（能用直线分开的数据集在现实中几乎没有），但它很适合用于教学，并且也是后面复杂算法的基础。
- **寻找分界线 ->  决策边界**: 通过学习历史数据找到了一条将这两类客户分开的直线
- **特征**: 自变量
    - 特征向量: 特征组
- **标签**: 因变量
- **乳腺癌实例**
    - scikit learn库（后面简称为sklearn）
- **监督式学习**: 如果提供的数据集有标签，并且在学习过程中用到了标签的算法
- **线性分类模型**: 通过特征向量的个数建立不同维数上的平面.
- **二分类线性模型**: 只能将数据分为两类，并且分界线是直线.
    - **多分类线性模型**



### 决策边界

- **分类和回归**: 监督式学习的应用场景总共有两个
- **感知机的思路**
    - **权重**：分别给这两个特征乘上不同的权重W1,W2. 最终表示为WnXn.
    - **阈值(threshold)**.
    - **发放**: 权重和大于阈值
    - **不发放**: 权重和小于阈值
    - 定义最终结果: ![](https://dandelionfs.oss-cn-beijing.aliyuncs.com/ml-result-formual.webp) 其中b表示阈值的负数
- **决策边界**: `d==0`时就是是n维空间中的超平面.
- **用点积来简化(超)平面**: ![](https://dandelionfs.oss-cn-beijing.aliyuncs.com/ml-perceptron-simply.webp)



### 感知机的暴力实现

- **寻找合适的w和b**: 结果最优.
- **点积的正负和夹角的大小**: 即a\*b与coso的联系
- **法向量**: 超平面下的法向量为W, 因为![\boldsymbol{w}\ \perp\ (\boldsymbol{w}\cdot\boldsymbol{x}+b=0)](data:image/svg+xml;utf8,%3Csvg%20xmlns%3Axlink%3D%22http%3A%2F%2Fwww.w3.org%2F1999%2Fxlink%22%20width%3D%2221.241ex%22%20height%3D%222.843ex%22%20style%3D%22font-size%3A14px%3Bvertical-align%3A%20-0.838ex%3B%22%20viewBox%3D%220%20-863.1%209145.5%201223.9%22%20role%3D%22img%22%20focusable%3D%22false%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20aria-labelledby%3D%22MathJax-SVG-1-Title%22%3E%0A%3Ctitle%20id%3D%22MathJax-SVG-1-Title%22%3E%5Cboldsymbol%7Bw%7D%5C%20%5Cperp%5C%20(%5Cboldsymbol%7Bw%7D%5Ccdot%5Cboldsymbol%7Bx%7D%2Bb%3D0)%3C%2Ftitle%3E%0A%3Cdefs%20aria-hidden%3D%22true%22%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMATHBI-77%22%20d%3D%22M636%20367Q636%20400%20664%20426T719%20453Q748%20453%20772%20431T796%20357Q796%20321%20782%20256T727%20112T633%206Q604%20-8%20567%20-8Q466%20-8%20415%2043Q414%2042%20410%2038T403%2031T396%2025T388%2018T378%2011T367%205T355%200T340%20-4T324%20-7T306%20-8Q249%20-8%20209%205T151%2040T125%2084T117%20129Q117%20176%20153%20274T190%20388Q190%20408%20158%20396Q112%20376%2090%20306Q85%20288%2081%20285T61%20282H55H44Q24%20282%2024%20296Q24%20305%2034%20328T63%20380T114%20430T187%20452Q240%20452%20274%20427T309%20362Q309%20346%20275%20255T240%20117Q240%2043%20317%2043Q325%2043%20333%2045T347%2050T359%2057T369%2066T377%2075T383%2083T388%2090L390%2095Q390%2099%20389%20110T387%20129Q387%20139%20391%20167Q393%20177%20419%20282T448%20396Q456%20414%20475%20429T519%20444Q546%20444%20559%20428T572%20397Q572%20384%20542%20265T511%20114Q511%2043%20579%2043Q608%2043%20633%2066T673%20122T699%20188T714%20244L718%20267Q718%20291%20673%20315Q636%20335%20636%20367Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMAIN-22A5%22%20d%3D%22M369%20652Q369%20653%20370%20655T372%20658T375%20662T379%20665T384%20667T391%20668Q402%20666%20409%20653V40H708Q723%2032%20723%2020T708%200H71Q70%200%2067%202T59%209T55%2020T59%2031T66%2038T71%2040H369V652Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMAIN-28%22%20d%3D%22M94%20250Q94%20319%20104%20381T127%20488T164%20576T202%20643T244%20695T277%20729T302%20750H315H319Q333%20750%20333%20741Q333%20738%20316%20720T275%20667T226%20581T184%20443T167%20250T184%2058T225%20-81T274%20-167T316%20-220T333%20-241Q333%20-250%20318%20-250H315H302L274%20-226Q180%20-141%20137%20-14T94%20250Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMAIN-22C5%22%20d%3D%22M78%20250Q78%20274%2095%20292T138%20310Q162%20310%20180%20294T199%20251Q199%20226%20182%20208T139%20190T96%20207T78%20250Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMATHBI-78%22%20d%3D%22M74%20282H63Q43%20282%2043%20296Q43%20298%2045%20307T56%20332T76%20365T110%20401T159%20433Q200%20451%20233%20451H236Q273%20451%20282%20450Q358%20437%20382%20400L392%20410Q434%20452%20483%20452Q538%20452%20568%20421T599%20346Q599%20303%20573%20280T517%20256Q494%20256%20478%20270T462%20308Q462%20343%20488%20367Q501%20377%20520%20385Q520%20386%20516%20389T502%20396T480%20400T462%20398Q429%20383%20415%20341Q354%20116%20354%2080T405%2044Q449%2044%20485%2074T535%20142Q539%20156%20542%20159T562%20162H568H579Q599%20162%20599%20148Q599%20135%20586%20111T550%2060T485%2012T397%20-8Q313%20-8%20266%2035L258%2044Q215%20-7%20161%20-7H156Q99%20-7%2071%2025T43%2095Q43%20143%2070%20165T125%20188Q148%20188%20164%20174T180%20136Q180%20101%20154%2077Q141%2067%20122%2059Q124%2054%20136%2049T161%2043Q183%2043%20200%2061T226%20103Q287%20328%20287%20364T236%20400Q200%20400%20164%20377T107%20302Q103%20288%20100%20285T80%20282H74Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMAIN-2B%22%20d%3D%22M56%20237T56%20250T70%20270H369V420L370%20570Q380%20583%20389%20583Q402%20583%20409%20568V270H707Q722%20262%20722%20250T707%20230H409V-68Q401%20-82%20391%20-82H389H387Q375%20-82%20369%20-68V230H70Q56%20237%2056%20250Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMATHI-62%22%20d%3D%22M73%20647Q73%20657%2077%20670T89%20683Q90%20683%20161%20688T234%20694Q246%20694%20246%20685T212%20542Q204%20508%20195%20472T180%20418L176%20399Q176%20396%20182%20402Q231%20442%20283%20442Q345%20442%20383%20396T422%20280Q422%20169%20343%2079T173%20-11Q123%20-11%2082%2027T40%20150V159Q40%20180%2048%20217T97%20414Q147%20611%20147%20623T109%20637Q104%20637%20101%20637H96Q86%20637%2083%20637T76%20640T73%20647ZM336%20325V331Q336%20405%20275%20405Q258%20405%20240%20397T207%20376T181%20352T163%20330L157%20322L136%20236Q114%20150%20114%20114Q114%2066%20138%2042Q154%2026%20178%2026Q211%2026%20245%2058Q270%2081%20285%20114T318%20219Q336%20291%20336%20325Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMAIN-3D%22%20d%3D%22M56%20347Q56%20360%2070%20367H707Q722%20359%20722%20347Q722%20336%20708%20328L390%20327H72Q56%20332%2056%20347ZM56%20153Q56%20168%2072%20173H708Q722%20163%20722%20153Q722%20140%20707%20133H70Q56%20140%2056%20153Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMAIN-30%22%20d%3D%22M96%20585Q152%20666%20249%20666Q297%20666%20345%20640T423%20548Q460%20465%20460%20320Q460%20165%20417%2083Q397%2041%20362%2016T301%20-15T250%20-22Q224%20-22%20198%20-16T137%2016T82%2083Q39%20165%2039%20320Q39%20494%2096%20585ZM321%20597Q291%20629%20250%20629Q208%20629%20178%20597Q153%20571%20145%20525T137%20333Q137%20175%20145%20125T181%2046Q209%2016%20250%2016Q290%2016%20318%2046Q347%2076%20354%20130T362%20333Q362%20478%20354%20524T321%20597Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMAIN-29%22%20d%3D%22M60%20749L64%20750Q69%20750%2074%20750H86L114%20726Q208%20641%20251%20514T294%20250Q294%20182%20284%20119T261%2012T224%20-76T186%20-143T145%20-194T113%20-227T90%20-246Q87%20-249%2086%20-250H74Q66%20-250%2063%20-250T58%20-247T55%20-238Q56%20-237%2066%20-225Q221%20-64%20221%20250T66%20725Q56%20737%2055%20738Q55%20746%2060%20749Z%22%3E%3C%2Fpath%3E%0A%3C%2Fdefs%3E%0A%3Cg%20stroke%3D%22currentColor%22%20fill%3D%22currentColor%22%20stroke-width%3D%220%22%20transform%3D%22matrix(1%200%200%20-1%200%200)%22%20aria-hidden%3D%22true%22%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMATHBI-77%22%20x%3D%220%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-22A5%22%20x%3D%221359%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-28%22%20x%3D%222665%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMATHBI-77%22%20x%3D%223055%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-22C5%22%20x%3D%224108%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMATHBI-78%22%20x%3D%224609%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-2B%22%20x%3D%225491%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMATHI-62%22%20x%3D%226491%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-3D%22%20x%3D%227199%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-30%22%20x%3D%228255%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-29%22%20x%3D%228756%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%3C%2Fg%3E%0A%3C%2Fsvg%3E)
-  **超平面的两侧**
    - d(a) > 0, W的方向
    - d(a)==0, 超平面上
    - d(a) < 0, W反方向
- **对错的判断**
    - W的方向 `y = 1` ; W的反方向 `y = -1`.
        - **分对**: ![y_i\cdot d(\boldsymbol{x_i}) > 0,\quad i=1,3,4,5](data:image/svg+xml;utf8,%3Csvg%20xmlns%3Axlink%3D%22http%3A%2F%2Fwww.w3.org%2F1999%2Fxlink%22%20width%3D%2228.343ex%22%20height%3D%222.843ex%22%20style%3D%22font-size%3A14px%3Bvertical-align%3A%20-0.838ex%3B%22%20viewBox%3D%220%20-863.1%2012203.3%201223.9%22%20role%3D%22img%22%20focusable%3D%22false%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20aria-labelledby%3D%22MathJax-SVG-1-Title%22%3E%0A%3Ctitle%20id%3D%22MathJax-SVG-1-Title%22%3Ey_i%5Ccdot%20d(%5Cboldsymbol%7Bx_i%7D)%20%26gt%3B%200%2C%5Cquad%20i%3D1%2C3%2C4%2C5%3C%2Ftitle%3E%0A%3Cdefs%20aria-hidden%3D%22true%22%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMATHI-79%22%20d%3D%22M21%20287Q21%20301%2036%20335T84%20406T158%20442Q199%20442%20224%20419T250%20355Q248%20336%20247%20334Q247%20331%20231%20288T198%20191T182%20105Q182%2062%20196%2045T238%2027Q261%2027%20281%2038T312%2061T339%2094Q339%2095%20344%20114T358%20173T377%20247Q415%20397%20419%20404Q432%20431%20462%20431Q475%20431%20483%20424T494%20412T496%20403Q496%20390%20447%20193T391%20-23Q363%20-106%20294%20-155T156%20-205Q111%20-205%2077%20-183T43%20-117Q43%20-95%2050%20-80T69%20-58T89%20-48T106%20-45Q150%20-45%20150%20-87Q150%20-107%20138%20-122T115%20-142T102%20-147L99%20-148Q101%20-153%20118%20-160T152%20-167H160Q177%20-167%20186%20-165Q219%20-156%20247%20-127T290%20-65T313%20-9T321%2021L315%2017Q309%2013%20296%206T270%20-6Q250%20-11%20231%20-11Q185%20-11%20150%2011T104%2082Q103%2089%20103%20113Q103%20170%20138%20262T173%20379Q173%20380%20173%20381Q173%20390%20173%20393T169%20400T158%20404H154Q131%20404%20112%20385T82%20344T65%20302T57%20280Q55%20278%2041%20278H27Q21%20284%2021%20287Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMATHI-69%22%20d%3D%22M184%20600Q184%20624%20203%20642T247%20661Q265%20661%20277%20649T290%20619Q290%20596%20270%20577T226%20557Q211%20557%20198%20567T184%20600ZM21%20287Q21%20295%2030%20318T54%20369T98%20420T158%20442Q197%20442%20223%20419T250%20357Q250%20340%20236%20301T196%20196T154%2083Q149%2061%20149%2051Q149%2026%20166%2026Q175%2026%20185%2029T208%2043T235%2078T260%20137Q263%20149%20265%20151T282%20153Q302%20153%20302%20143Q302%20135%20293%20112T268%2061T223%2011T161%20-11Q129%20-11%20102%2010T74%2074Q74%2091%2079%20106T122%20220Q160%20321%20166%20341T173%20380Q173%20404%20156%20404H154Q124%20404%2099%20371T61%20287Q60%20286%2059%20284T58%20281T56%20279T53%20278T49%20278T41%20278H27Q21%20284%2021%20287Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMAIN-22C5%22%20d%3D%22M78%20250Q78%20274%2095%20292T138%20310Q162%20310%20180%20294T199%20251Q199%20226%20182%20208T139%20190T96%20207T78%20250Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMATHI-64%22%20d%3D%22M366%20683Q367%20683%20438%20688T511%20694Q523%20694%20523%20686Q523%20679%20450%20384T375%2083T374%2068Q374%2026%20402%2026Q411%2027%20422%2035Q443%2055%20463%20131Q469%20151%20473%20152Q475%20153%20483%20153H487H491Q506%20153%20506%20145Q506%20140%20503%20129Q490%2079%20473%2048T445%208T417%20-8Q409%20-10%20393%20-10Q359%20-10%20336%205T306%2036L300%2051Q299%2052%20296%2050Q294%2048%20292%2046Q233%20-10%20172%20-10Q117%20-10%2075%2030T33%20157Q33%20205%2053%20255T101%20341Q148%20398%20195%20420T280%20442Q336%20442%20364%20400Q369%20394%20369%20396Q370%20400%20396%20505T424%20616Q424%20629%20417%20632T378%20637H357Q351%20643%20351%20645T353%20664Q358%20683%20366%20683ZM352%20326Q329%20405%20277%20405Q242%20405%20210%20374T160%20293Q131%20214%20119%20129Q119%20126%20119%20118T118%20106Q118%2061%20136%2044T179%2026Q233%2026%20290%2098L298%20109L352%20326Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMAIN-28%22%20d%3D%22M94%20250Q94%20319%20104%20381T127%20488T164%20576T202%20643T244%20695T277%20729T302%20750H315H319Q333%20750%20333%20741Q333%20738%20316%20720T275%20667T226%20581T184%20443T167%20250T184%2058T225%20-81T274%20-167T316%20-220T333%20-241Q333%20-250%20318%20-250H315H302L274%20-226Q180%20-141%20137%20-14T94%20250Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMATHBI-78%22%20d%3D%22M74%20282H63Q43%20282%2043%20296Q43%20298%2045%20307T56%20332T76%20365T110%20401T159%20433Q200%20451%20233%20451H236Q273%20451%20282%20450Q358%20437%20382%20400L392%20410Q434%20452%20483%20452Q538%20452%20568%20421T599%20346Q599%20303%20573%20280T517%20256Q494%20256%20478%20270T462%20308Q462%20343%20488%20367Q501%20377%20520%20385Q520%20386%20516%20389T502%20396T480%20400T462%20398Q429%20383%20415%20341Q354%20116%20354%2080T405%2044Q449%2044%20485%2074T535%20142Q539%20156%20542%20159T562%20162H568H579Q599%20162%20599%20148Q599%20135%20586%20111T550%2060T485%2012T397%20-8Q313%20-8%20266%2035L258%2044Q215%20-7%20161%20-7H156Q99%20-7%2071%2025T43%2095Q43%20143%2070%20165T125%20188Q148%20188%20164%20174T180%20136Q180%20101%20154%2077Q141%2067%20122%2059Q124%2054%20136%2049T161%2043Q183%2043%20200%2061T226%20103Q287%20328%20287%20364T236%20400Q200%20400%20164%20377T107%20302Q103%20288%20100%20285T80%20282H74Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMATHBI-69%22%20d%3D%22M205%20615Q205%20646%20229%20670T283%20694Q310%20694%20324%20679T339%20641Q339%20610%20315%20586T258%20562Q235%20562%20220%20577T205%20615ZM24%20296Q24%20305%2034%20328T63%20380T115%20430T187%20452Q205%20452%20223%20448T262%20435T295%20406T308%20360Q308%20345%20287%20290T240%20170T207%2087Q202%2067%20202%2057Q202%2042%20215%2042Q235%2042%20257%2064Q288%2092%20302%20140Q307%20156%20310%20159T330%20162H336H347Q367%20162%20367%20148Q367%20140%20357%20117T329%2065T276%2014T201%20-8Q158%20-8%20121%2015T83%2084Q83%20104%20133%20229T184%20358Q189%20376%20189%20388Q189%20402%20177%20402Q156%20402%20134%20380Q103%20352%2089%20304Q84%20288%2081%20285T61%20282H55H44Q24%20282%2024%20296Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMAIN-29%22%20d%3D%22M60%20749L64%20750Q69%20750%2074%20750H86L114%20726Q208%20641%20251%20514T294%20250Q294%20182%20284%20119T261%2012T224%20-76T186%20-143T145%20-194T113%20-227T90%20-246Q87%20-249%2086%20-250H74Q66%20-250%2063%20-250T58%20-247T55%20-238Q56%20-237%2066%20-225Q221%20-64%20221%20250T66%20725Q56%20737%2055%20738Q55%20746%2060%20749Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMAIN-3E%22%20d%3D%22M84%20520Q84%20528%2088%20533T96%20539L99%20540Q106%20540%20253%20471T544%20334L687%20265Q694%20260%20694%20250T687%20235Q685%20233%20395%2096L107%20-40H101Q83%20-38%2083%20-20Q83%20-19%2083%20-17Q82%20-10%2098%20-1Q117%209%20248%2071Q326%20108%20378%20132L626%20250L378%20368Q90%20504%2086%20509Q84%20513%2084%20520Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMAIN-30%22%20d%3D%22M96%20585Q152%20666%20249%20666Q297%20666%20345%20640T423%20548Q460%20465%20460%20320Q460%20165%20417%2083Q397%2041%20362%2016T301%20-15T250%20-22Q224%20-22%20198%20-16T137%2016T82%2083Q39%20165%2039%20320Q39%20494%2096%20585ZM321%20597Q291%20629%20250%20629Q208%20629%20178%20597Q153%20571%20145%20525T137%20333Q137%20175%20145%20125T181%2046Q209%2016%20250%2016Q290%2016%20318%2046Q347%2076%20354%20130T362%20333Q362%20478%20354%20524T321%20597Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMAIN-2C%22%20d%3D%22M78%2035T78%2060T94%20103T137%20121Q165%20121%20187%2096T210%208Q210%20-27%20201%20-60T180%20-117T154%20-158T130%20-185T117%20-194Q113%20-194%20104%20-185T95%20-172Q95%20-168%20106%20-156T131%20-126T157%20-76T173%20-3V9L172%208Q170%207%20167%206T161%203T152%201T140%200Q113%200%2096%2017Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMAIN-3D%22%20d%3D%22M56%20347Q56%20360%2070%20367H707Q722%20359%20722%20347Q722%20336%20708%20328L390%20327H72Q56%20332%2056%20347ZM56%20153Q56%20168%2072%20173H708Q722%20163%20722%20153Q722%20140%20707%20133H70Q56%20140%2056%20153Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMAIN-31%22%20d%3D%22M213%20578L200%20573Q186%20568%20160%20563T102%20556H83V602H102Q149%20604%20189%20617T245%20641T273%20663Q275%20666%20285%20666Q294%20666%20302%20660V361L303%2061Q310%2054%20315%2052T339%2048T401%2046H427V0H416Q395%203%20257%203Q121%203%20100%200H88V46H114Q136%2046%20152%2046T177%2047T193%2050T201%2052T207%2057T213%2061V578Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMAIN-33%22%20d%3D%22M127%20463Q100%20463%2085%20480T69%20524Q69%20579%20117%20622T233%20665Q268%20665%20277%20664Q351%20652%20390%20611T430%20522Q430%20470%20396%20421T302%20350L299%20348Q299%20347%20308%20345T337%20336T375%20315Q457%20262%20457%20175Q457%2096%20395%2037T238%20-22Q158%20-22%20100%2021T42%20130Q42%20158%2060%20175T105%20193Q133%20193%20151%20175T169%20130Q169%20119%20166%20110T159%2094T148%2082T136%2074T126%2070T118%2067L114%2066Q165%2021%20238%2021Q293%2021%20321%2074Q338%20107%20338%20175V195Q338%20290%20274%20322Q259%20328%20213%20329L171%20330L168%20332Q166%20335%20166%20348Q166%20366%20174%20366Q202%20366%20232%20371Q266%20376%20294%20413T322%20525V533Q322%20590%20287%20612Q265%20626%20240%20626Q208%20626%20181%20615T143%20592T132%20580H135Q138%20579%20143%20578T153%20573T165%20566T175%20555T183%20540T186%20520Q186%20498%20172%20481T127%20463Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMAIN-34%22%20d%3D%22M462%200Q444%203%20333%203Q217%203%20199%200H190V46H221Q241%2046%20248%2046T265%2048T279%2053T286%2061Q287%2063%20287%20115V165H28V211L179%20442Q332%20674%20334%20675Q336%20677%20355%20677H373L379%20671V211H471V165H379V114Q379%2073%20379%2066T385%2054Q393%2047%20442%2046H471V0H462ZM293%20211V545L74%20212L183%20211H293Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMAIN-35%22%20d%3D%22M164%20157Q164%20133%20148%20117T109%20101H102Q148%2022%20224%2022Q294%2022%20326%2082Q345%20115%20345%20210Q345%20313%20318%20349Q292%20382%20260%20382H254Q176%20382%20136%20314Q132%20307%20129%20306T114%20304Q97%20304%2095%20310Q93%20314%2093%20485V614Q93%20664%2098%20664Q100%20666%20102%20666Q103%20666%20123%20658T178%20642T253%20634Q324%20634%20389%20662Q397%20666%20402%20666Q410%20666%20410%20648V635Q328%20538%20205%20538Q174%20538%20149%20544L139%20546V374Q158%20388%20169%20396T205%20412T256%20420Q337%20420%20393%20355T449%20201Q449%20109%20385%2044T229%20-22Q148%20-22%2099%2032T50%20154Q50%20178%2061%20192T84%20210T107%20214Q132%20214%20148%20197T164%20157Z%22%3E%3C%2Fpath%3E%0A%3C%2Fdefs%3E%0A%3Cg%20stroke%3D%22currentColor%22%20fill%3D%22currentColor%22%20stroke-width%3D%220%22%20transform%3D%22matrix(1%200%200%20-1%200%200)%22%20aria-hidden%3D%22true%22%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMATHI-79%22%20x%3D%220%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20transform%3D%22scale(0.707)%22%20xlink%3Ahref%3D%22%23E1-MJMATHI-69%22%20x%3D%22693%22%20y%3D%22-213%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-22C5%22%20x%3D%221057%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMATHI-64%22%20x%3D%221557%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-28%22%20x%3D%222081%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%3Cg%20transform%3D%22translate(2470%2C0)%22%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMATHBI-78%22%20x%3D%220%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20transform%3D%22scale(0.707)%22%20xlink%3Ahref%3D%22%23E1-MJMATHBI-69%22%20x%3D%22932%22%20y%3D%22-213%22%3E%3C%2Fuse%3E%0A%3C%2Fg%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-29%22%20x%3D%223516%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-3E%22%20x%3D%224184%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-30%22%20x%3D%225240%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-2C%22%20x%3D%225741%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMATHI-69%22%20x%3D%227186%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-3D%22%20x%3D%227809%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-31%22%20x%3D%228865%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-2C%22%20x%3D%229366%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-33%22%20x%3D%229811%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-2C%22%20x%3D%2210311%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-34%22%20x%3D%2210757%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-2C%22%20x%3D%2211257%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-35%22%20x%3D%2211702%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%3C%2Fg%3E%0A%3C%2Fsvg%3E) 
        - **分错**(分错边或分到边界线): ![y_i\cdot d(\boldsymbol{x_i}) \le 0,\quad i=2,6](data:image/svg+xml;utf8,%3Csvg%20xmlns%3Axlink%3D%22http%3A%2F%2Fwww.w3.org%2F1999%2Fxlink%22%20width%3D%2223.95ex%22%20height%3D%222.843ex%22%20style%3D%22font-size%3A14px%3Bvertical-align%3A%20-0.838ex%3B%22%20viewBox%3D%220%20-863.1%2010311.9%201223.9%22%20role%3D%22img%22%20focusable%3D%22false%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20aria-labelledby%3D%22MathJax-SVG-1-Title%22%3E%0A%3Ctitle%20id%3D%22MathJax-SVG-1-Title%22%3Ey_i%5Ccdot%20d(%5Cboldsymbol%7Bx_i%7D)%20%5Cle%200%2C%5Cquad%20i%3D2%2C6%3C%2Ftitle%3E%0A%3Cdefs%20aria-hidden%3D%22true%22%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMATHI-79%22%20d%3D%22M21%20287Q21%20301%2036%20335T84%20406T158%20442Q199%20442%20224%20419T250%20355Q248%20336%20247%20334Q247%20331%20231%20288T198%20191T182%20105Q182%2062%20196%2045T238%2027Q261%2027%20281%2038T312%2061T339%2094Q339%2095%20344%20114T358%20173T377%20247Q415%20397%20419%20404Q432%20431%20462%20431Q475%20431%20483%20424T494%20412T496%20403Q496%20390%20447%20193T391%20-23Q363%20-106%20294%20-155T156%20-205Q111%20-205%2077%20-183T43%20-117Q43%20-95%2050%20-80T69%20-58T89%20-48T106%20-45Q150%20-45%20150%20-87Q150%20-107%20138%20-122T115%20-142T102%20-147L99%20-148Q101%20-153%20118%20-160T152%20-167H160Q177%20-167%20186%20-165Q219%20-156%20247%20-127T290%20-65T313%20-9T321%2021L315%2017Q309%2013%20296%206T270%20-6Q250%20-11%20231%20-11Q185%20-11%20150%2011T104%2082Q103%2089%20103%20113Q103%20170%20138%20262T173%20379Q173%20380%20173%20381Q173%20390%20173%20393T169%20400T158%20404H154Q131%20404%20112%20385T82%20344T65%20302T57%20280Q55%20278%2041%20278H27Q21%20284%2021%20287Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMATHI-69%22%20d%3D%22M184%20600Q184%20624%20203%20642T247%20661Q265%20661%20277%20649T290%20619Q290%20596%20270%20577T226%20557Q211%20557%20198%20567T184%20600ZM21%20287Q21%20295%2030%20318T54%20369T98%20420T158%20442Q197%20442%20223%20419T250%20357Q250%20340%20236%20301T196%20196T154%2083Q149%2061%20149%2051Q149%2026%20166%2026Q175%2026%20185%2029T208%2043T235%2078T260%20137Q263%20149%20265%20151T282%20153Q302%20153%20302%20143Q302%20135%20293%20112T268%2061T223%2011T161%20-11Q129%20-11%20102%2010T74%2074Q74%2091%2079%20106T122%20220Q160%20321%20166%20341T173%20380Q173%20404%20156%20404H154Q124%20404%2099%20371T61%20287Q60%20286%2059%20284T58%20281T56%20279T53%20278T49%20278T41%20278H27Q21%20284%2021%20287Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMAIN-22C5%22%20d%3D%22M78%20250Q78%20274%2095%20292T138%20310Q162%20310%20180%20294T199%20251Q199%20226%20182%20208T139%20190T96%20207T78%20250Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMATHI-64%22%20d%3D%22M366%20683Q367%20683%20438%20688T511%20694Q523%20694%20523%20686Q523%20679%20450%20384T375%2083T374%2068Q374%2026%20402%2026Q411%2027%20422%2035Q443%2055%20463%20131Q469%20151%20473%20152Q475%20153%20483%20153H487H491Q506%20153%20506%20145Q506%20140%20503%20129Q490%2079%20473%2048T445%208T417%20-8Q409%20-10%20393%20-10Q359%20-10%20336%205T306%2036L300%2051Q299%2052%20296%2050Q294%2048%20292%2046Q233%20-10%20172%20-10Q117%20-10%2075%2030T33%20157Q33%20205%2053%20255T101%20341Q148%20398%20195%20420T280%20442Q336%20442%20364%20400Q369%20394%20369%20396Q370%20400%20396%20505T424%20616Q424%20629%20417%20632T378%20637H357Q351%20643%20351%20645T353%20664Q358%20683%20366%20683ZM352%20326Q329%20405%20277%20405Q242%20405%20210%20374T160%20293Q131%20214%20119%20129Q119%20126%20119%20118T118%20106Q118%2061%20136%2044T179%2026Q233%2026%20290%2098L298%20109L352%20326Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMAIN-28%22%20d%3D%22M94%20250Q94%20319%20104%20381T127%20488T164%20576T202%20643T244%20695T277%20729T302%20750H315H319Q333%20750%20333%20741Q333%20738%20316%20720T275%20667T226%20581T184%20443T167%20250T184%2058T225%20-81T274%20-167T316%20-220T333%20-241Q333%20-250%20318%20-250H315H302L274%20-226Q180%20-141%20137%20-14T94%20250Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMATHBI-78%22%20d%3D%22M74%20282H63Q43%20282%2043%20296Q43%20298%2045%20307T56%20332T76%20365T110%20401T159%20433Q200%20451%20233%20451H236Q273%20451%20282%20450Q358%20437%20382%20400L392%20410Q434%20452%20483%20452Q538%20452%20568%20421T599%20346Q599%20303%20573%20280T517%20256Q494%20256%20478%20270T462%20308Q462%20343%20488%20367Q501%20377%20520%20385Q520%20386%20516%20389T502%20396T480%20400T462%20398Q429%20383%20415%20341Q354%20116%20354%2080T405%2044Q449%2044%20485%2074T535%20142Q539%20156%20542%20159T562%20162H568H579Q599%20162%20599%20148Q599%20135%20586%20111T550%2060T485%2012T397%20-8Q313%20-8%20266%2035L258%2044Q215%20-7%20161%20-7H156Q99%20-7%2071%2025T43%2095Q43%20143%2070%20165T125%20188Q148%20188%20164%20174T180%20136Q180%20101%20154%2077Q141%2067%20122%2059Q124%2054%20136%2049T161%2043Q183%2043%20200%2061T226%20103Q287%20328%20287%20364T236%20400Q200%20400%20164%20377T107%20302Q103%20288%20100%20285T80%20282H74Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMATHBI-69%22%20d%3D%22M205%20615Q205%20646%20229%20670T283%20694Q310%20694%20324%20679T339%20641Q339%20610%20315%20586T258%20562Q235%20562%20220%20577T205%20615ZM24%20296Q24%20305%2034%20328T63%20380T115%20430T187%20452Q205%20452%20223%20448T262%20435T295%20406T308%20360Q308%20345%20287%20290T240%20170T207%2087Q202%2067%20202%2057Q202%2042%20215%2042Q235%2042%20257%2064Q288%2092%20302%20140Q307%20156%20310%20159T330%20162H336H347Q367%20162%20367%20148Q367%20140%20357%20117T329%2065T276%2014T201%20-8Q158%20-8%20121%2015T83%2084Q83%20104%20133%20229T184%20358Q189%20376%20189%20388Q189%20402%20177%20402Q156%20402%20134%20380Q103%20352%2089%20304Q84%20288%2081%20285T61%20282H55H44Q24%20282%2024%20296Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMAIN-29%22%20d%3D%22M60%20749L64%20750Q69%20750%2074%20750H86L114%20726Q208%20641%20251%20514T294%20250Q294%20182%20284%20119T261%2012T224%20-76T186%20-143T145%20-194T113%20-227T90%20-246Q87%20-249%2086%20-250H74Q66%20-250%2063%20-250T58%20-247T55%20-238Q56%20-237%2066%20-225Q221%20-64%20221%20250T66%20725Q56%20737%2055%20738Q55%20746%2060%20749Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMAIN-2264%22%20d%3D%22M674%20636Q682%20636%20688%20630T694%20615T687%20601Q686%20600%20417%20472L151%20346L399%20228Q687%2092%20691%2087Q694%2081%20694%2076Q694%2058%20676%2056H670L382%20192Q92%20329%2090%20331Q83%20336%2083%20348Q84%20359%2096%20365Q104%20369%20382%20500T665%20634Q669%20636%20674%20636ZM84%20-118Q84%20-108%2099%20-98H678Q694%20-104%20694%20-118Q694%20-130%20679%20-138H98Q84%20-131%2084%20-118Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMAIN-30%22%20d%3D%22M96%20585Q152%20666%20249%20666Q297%20666%20345%20640T423%20548Q460%20465%20460%20320Q460%20165%20417%2083Q397%2041%20362%2016T301%20-15T250%20-22Q224%20-22%20198%20-16T137%2016T82%2083Q39%20165%2039%20320Q39%20494%2096%20585ZM321%20597Q291%20629%20250%20629Q208%20629%20178%20597Q153%20571%20145%20525T137%20333Q137%20175%20145%20125T181%2046Q209%2016%20250%2016Q290%2016%20318%2046Q347%2076%20354%20130T362%20333Q362%20478%20354%20524T321%20597Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMAIN-2C%22%20d%3D%22M78%2035T78%2060T94%20103T137%20121Q165%20121%20187%2096T210%208Q210%20-27%20201%20-60T180%20-117T154%20-158T130%20-185T117%20-194Q113%20-194%20104%20-185T95%20-172Q95%20-168%20106%20-156T131%20-126T157%20-76T173%20-3V9L172%208Q170%207%20167%206T161%203T152%201T140%200Q113%200%2096%2017Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMAIN-3D%22%20d%3D%22M56%20347Q56%20360%2070%20367H707Q722%20359%20722%20347Q722%20336%20708%20328L390%20327H72Q56%20332%2056%20347ZM56%20153Q56%20168%2072%20173H708Q722%20163%20722%20153Q722%20140%20707%20133H70Q56%20140%2056%20153Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMAIN-32%22%20d%3D%22M109%20429Q82%20429%2066%20447T50%20491Q50%20562%20103%20614T235%20666Q326%20666%20387%20610T449%20465Q449%20422%20429%20383T381%20315T301%20241Q265%20210%20201%20149L142%2093L218%2092Q375%2092%20385%2097Q392%2099%20409%20186V189H449V186Q448%20183%20436%2095T421%203V0H50V19V31Q50%2038%2056%2046T86%2081Q115%20113%20136%20137Q145%20147%20170%20174T204%20211T233%20244T261%20278T284%20308T305%20340T320%20369T333%20401T340%20431T343%20464Q343%20527%20309%20573T212%20619Q179%20619%20154%20602T119%20569T109%20550Q109%20549%20114%20549Q132%20549%20151%20535T170%20489Q170%20464%20154%20447T109%20429Z%22%3E%3C%2Fpath%3E%0A%3Cpath%20stroke-width%3D%221%22%20id%3D%22E1-MJMAIN-36%22%20d%3D%22M42%20313Q42%20476%20123%20571T303%20666Q372%20666%20402%20630T432%20550Q432%20525%20418%20510T379%20495Q356%20495%20341%20509T326%20548Q326%20592%20373%20601Q351%20623%20311%20626Q240%20626%20194%20566Q147%20500%20147%20364L148%20360Q153%20366%20156%20373Q197%20433%20263%20433H267Q313%20433%20348%20414Q372%20400%20396%20374T435%20317Q456%20268%20456%20210V192Q456%20169%20451%20149Q440%2090%20387%2034T253%20-22Q225%20-22%20199%20-14T143%2016T92%2075T56%20172T42%20313ZM257%20397Q227%20397%20205%20380T171%20335T154%20278T148%20216Q148%20133%20160%2097T198%2039Q222%2021%20251%2021Q302%2021%20329%2059Q342%2077%20347%20104T352%20209Q352%20289%20347%20316T329%20361Q302%20397%20257%20397Z%22%3E%3C%2Fpath%3E%0A%3C%2Fdefs%3E%0A%3Cg%20stroke%3D%22currentColor%22%20fill%3D%22currentColor%22%20stroke-width%3D%220%22%20transform%3D%22matrix(1%200%200%20-1%200%200)%22%20aria-hidden%3D%22true%22%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMATHI-79%22%20x%3D%220%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20transform%3D%22scale(0.707)%22%20xlink%3Ahref%3D%22%23E1-MJMATHI-69%22%20x%3D%22693%22%20y%3D%22-213%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-22C5%22%20x%3D%221057%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMATHI-64%22%20x%3D%221557%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-28%22%20x%3D%222081%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%3Cg%20transform%3D%22translate(2470%2C0)%22%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMATHBI-78%22%20x%3D%220%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20transform%3D%22scale(0.707)%22%20xlink%3Ahref%3D%22%23E1-MJMATHBI-69%22%20x%3D%22932%22%20y%3D%22-213%22%3E%3C%2Fuse%3E%0A%3C%2Fg%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-29%22%20x%3D%223516%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-2264%22%20x%3D%224184%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-30%22%20x%3D%225240%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-2C%22%20x%3D%225741%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMATHI-69%22%20x%3D%227186%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-3D%22%20x%3D%227809%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-32%22%20x%3D%228865%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-2C%22%20x%3D%229366%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%20%3Cuse%20xlink%3Ahref%3D%22%23E1-MJMAIN-36%22%20x%3D%229811%22%20y%3D%220%22%3E%3C%2Fuse%3E%0A%3C%2Fg%3E%0A%3C%2Fsvg%3E) 
- **错误的纠正**
    - **拉近**: 平行四边形的对角线纠正.
    - **推远**: 平行四边形的平移纠正.
        - **错误的公式**: ![](https://dandelionfs.oss-cn-beijing.aliyuncs.com/ml-perceptron-error-correct1.webp)
        - **纠正过程**: ![](https://dandelionfs.oss-cn-beijing.aliyuncs.com/ml-perceptron-error-correct2.webp)
        - **纠正结果**: ![](https://dandelionfs.oss-cn-beijing.aliyuncs.com/ml-perceptron-error-correct3.webp)
- **错误纠正的例子**
- **找到决策边界**
- **算法规范化**
    - 初始化![](https://dandelionfs.oss-cn-beijing.aliyuncs.com/ml-perceptron-algo2.webp)
    - 迭代![](https://dandelionfs.oss-cn-beijing.aliyuncs.com/ml-perceptron-algo1.webp)

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import Perceptron
from matplotlib.colors import ListedColormap

# 初始化 w 和 b，np.array 相当于定义向量
w, b = np.array([0, 0]), 0 

# 定义 d(x) 函数
def d(x):
    return np.dot(w,x)+b # np.dot 是向量的点积

# 历史信用卡发行数据
# 这里的数据集不能随便修改，否则下面的暴力实现可能停不下来
X = np.array([[5,2], [3,2], [2,7], [1,4], [6,1], [4,5]])
y = np.array([-1, -1, 1, 1, -1, 1])

# 感知机的暴力实现
is_modified = True # 记录是否有分错的点
while is_modified: # 循环，直到没有分错的点
    is_modified = False

    # 顺序遍及数据集 X
    for xi, yi in zip(X, y):
        # 如果有分错的
        if yi*d(xi) <= 0:
            # 更新法向量 w 和 b
            w, b = w + yi*xi, b + yi
            is_modified = True
            break

# 下面是绘制的代码，主要展示暴力实现的结果，看不懂也没有关系
def make_meshgrid(x, y, h=.02):
    """Create a mesh of points to plot in

    Parameters
    ----------
    x: data to base x-axis meshgrid on
    y: data to base y-axis meshgrid on
    h: stepsize for meshgrid, optional

    Returns
    -------
    xx, yy : ndarray
    """
    x_min, x_max = x.min() - 1, x.max() + 1
    y_min, y_max = y.min() - 1, y.max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                         np.arange(y_min, y_max, h))
    return xx, yy

def plot_contours(ax, clf, xx, yy, **params):
    """Plot the decision boundaries for a classifier.

    Parameters
    ----------
    ax: matplotlib axes object
    clf: a classifier
    xx: meshgrid ndarray
    yy: meshgrid ndarray
    params: dictionary of params to pass to contourf, optional
    """
    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)
    out = ax.contourf(xx, yy, Z, **params)
    return out

# 训练 skrlearn 中的感知机，这里是为了借用该感知机的接口，便于绘制决策区域
clf = Perceptron().fit(X, y)
# 根据上面暴力实现得到的 w 和 b 来修改感知机
clf.coef_[0][0], clf.coef_[0][1], clf.intercept_[0] = w[0], w[1], b

# 设置字体大小
plt.rcParams.update({'font.size': 14})
# 设置画布和坐标系
fig, ax = plt.subplots(figsize = (6, 3), nrows=1, ncols=1)
fig.subplots_adjust(left=0.25, right=0.75, top=0.999, bottom=0.001)
ax.set_xticks(()),ax.set_yticks(())

cm = ListedColormap(('blue', 'red'))
markers = ('x', 'o')

# 决定绘制区域的大小
X0, X1 = X[:, 0], X[:, 1]
xx, yy = make_meshgrid(X0, X1)
ax.set_xlim(xx.min(), xx.max())
ax.set_ylim(yy.min(), yy.max())

# 绘制决策区域
plot_contours(ax, clf, xx, yy, cmap=cm, alpha=0.4)

# 绘制决策直线
lx = np.linspace(xx.min(), xx.max())
ly = - w[0] / w[1] * lx  - b / w[1]
ax.plot(lx, ly, 'k-')

# 根据类别不同，绘制不同形状的点
vmin, vmax = min(y), max(y)
for cl, m in zip(np.unique(y), markers):
  ax.scatter(x=X0[y==cl], y=X1[y==cl], c=y[y==cl], alpha=1, vmin = vmin, vmax = vmax, cmap=cm, edgecolors='k', marker = m)

plt.show()
```



### 线性可分

- **Novikoff 定理:** 线性可分 (Linear Separability) 的数据集, 暴力实现总会停止. 即总是存在`Yi * d(X) > 0 `.
    - 暴力实现的收敛性.最后的结果 <img src="https://dandelionfs.oss-cn-beijing.aliyuncs.com/ml-perceptron-up-bound.webp" style='display: inline;margin:0;'>
    - 实验代码如上. 默认循环很多次还没有停下来就说明是线性不可分的.
- **轮廓线 **(近似凸包 (Convex hull) : 如果轮廓线不相交就是线性可分

```python
# 载入必要的库
from shapely.geometry import Polygon
from scipy.spatial import ConvexHull
import numpy as np

# 线性可分数据集
X1 = np.array([[1. , 0.2], [1.1, 0.1], [1.2, 0.2], [1.3, 0.2], [1.3, 0.3], [1.3, 0.4], 
    [1.4, 0.1], [1.4, 0.2], [1.4, 0.3], [1.5, 0.1], [1.5, 0.2], [1.5, 0.3], [1.5, 0.4], 
    [1.6, 0.2], [1.6, 0.4], [1.6, 0.6], [1.7, 0.2], [1.7, 0.3], [1.7, 0.4], [1.7, 0.5], 
    [1.9, 0.2], [1.9, 0.4], [3.3, 1. ], [3. , 1.1], [3.7, 1. ], [3.6, 1.3], [3.5, 1. ], 
    [3.8, 1.1], [3.9, 1.1], [3.9, 1.2], [3.9, 1.4], [4. , 1. ], [4. , 1.2], [4. , 1.3],
    [4.1, 1. ], [4.1, 1.3], [4.2, 1.2], [4.2, 1.3], [4.2, 1.5], [4.3, 1.3], [4.3, 1.3], 
    [4.4, 1.3], [4.4, 1.2], [4.4, 1.4], [4.5, 1.3], [4.5, 1.5], [4.5, 1.6], [4.6, 1.3], 
    [4.6, 1.4], [4.6, 1.5], [4.7, 1.2], [4.7, 1.4], [4.7, 1.5], [4.7, 1.6], [4.8, 1.8], 
    [4.9, 1.5], [4.8, 1.4], [5. , 1.7], [5.1, 1.6], 
    ])
y1 = np.array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 
    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    1, 1, 1, 1, ])

# 计算X1数据集中两种数据的凸包
hull10 = ConvexHull(X1[y1==-1])
hull11 = ConvexHull(X1[y1==1])
# 取出凸包的边界点，构造两个多边形（即轮廓线）
p10 = Polygon(hull10.points[hull10.vertices])
p11 = Polygon(hull11.points[hull11.vertices])
# 这两个多边形不相交，即线性可分
print('两个多边形相交为 {} '.format(p10.intersects(p11)))


# 非线性可分数据集
X2 = np.array([[3. , 1.1], [3.3, 1. ], [3.5, 1. ], [3.6, 1.3], [3.7, 1. ], [3.8, 1.1], 
    [3.9, 1.1], [3.9, 1.2], [3.9, 1.4], [4. , 1. ], [4. , 1.2], [4. , 1.3], [4.1, 1. ], 
    [4.1, 1.3], [4.2, 1.2], [4.2, 1.3], [4.2, 1.5], [4.3, 1.3], [4.4, 1.2], [4.4, 1.3], [4.4, 1.4], 
    [4.5, 1.3], [4.5, 1.5], [4.5, 1.6], [4.5, 1.7], [4.6, 1.3], [4.6, 1.4], [4.6, 1.5], [4.7, 1.2], 
    [4.7, 1.4], [4.7, 1.5], [4.7, 1.6], [4.8, 1.4], [4.8, 1.8], [4.9, 1.5], [4.9, 1.8], [4.9, 2. ], 
    [5. , 1.5], [5. , 1.7], [5. , 1.9], [5. , 2. ], [5.1, 1.5], [5.1, 1.6], [5.1, 1.8], [5.1, 1.9], 
    [5.1, 2. ], [5.1, 2.3], [5.1, 2.4], [5.2, 2. ], [5.2, 2.3], [5.3, 1.9], [5.3, 2.3], [5.4, 2.1], 
    [5.4, 2.3], [5.5, 1.8], [5.5, 2.1], [5.6, 1.4], [5.6, 1.8], [5.6, 2.1], [5.6, 2.2], [5.6, 2.4], 
    [5.7, 2.1], [5.7, 2.3], [5.7, 2.5], [5.8, 1.6], [5.8, 1.8], [5.8, 2.2], [5.9, 2.1], [5.9, 2.3], 
    [6. , 1.8], [6. , 2.5], [6.1, 1.9], [6.1, 2.3], [6.1, 2.5], [6.3, 1.8], [6.4, 2. ], [6.6, 2.1], 
    [6.7, 2. ], [6.7, 2.2], [6.9, 2.3], ])
y2 = np.array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 
    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, -1, -1, -1, -1, 1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 
    1, 1,  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ])

# 分别计算X2数据集中两种数据的凸包
hull20 = ConvexHull(X2[y2==-1])
hull21 = ConvexHull(X2[y2==1])
# 取出凸包的边界点，构造两个多边形（即轮廓线）
p20 = Polygon(hull20.points[hull20.vertices])
p21 = Polygon(hull21.points[hull21.vertices])
# 这两个多边形相交，即线性不可分
print('两个多边形相交为 {} '.format(p20.intersects(p21)))
```

```python
# 引入必要的库
from matplotlib.colors import ListedColormap
from scipy.spatial import ConvexHull
from shapely.geometry import Polygon
import numpy as np
import matplotlib.pyplot as plt

# 以下是计算凸包的代码
# 线性可分数据集
X1 = np.array([[1. , 0.2], [1.1, 0.1], [1.2, 0.2], [1.3, 0.2], [1.3, 0.3], [1.3, 0.4], 
    [1.4, 0.1], [1.4, 0.2], [1.4, 0.3], [1.5, 0.1], [1.5, 0.2], [1.5, 0.3], [1.5, 0.4], 
    [1.6, 0.2], [1.6, 0.4], [1.6, 0.6], [1.7, 0.2], [1.7, 0.3], [1.7, 0.4], [1.7, 0.5], 
    [1.9, 0.2], [1.9, 0.4], [3.3, 1. ], [3. , 1.1], [3.7, 1. ], [3.6, 1.3], [3.5, 1. ], 
    [3.8, 1.1], [3.9, 1.1], [3.9, 1.2], [3.9, 1.4], [4. , 1. ], [4. , 1.2], [4. , 1.3],
    [4.1, 1. ], [4.1, 1.3], [4.2, 1.2], [4.2, 1.3], [4.2, 1.5], [4.3, 1.3], [4.3, 1.3], 
    [4.4, 1.3], [4.4, 1.2], [4.4, 1.4], [4.5, 1.3], [4.5, 1.5], [4.5, 1.6], [4.6, 1.3], 
    [4.6, 1.4], [4.6, 1.5], [4.7, 1.2], [4.7, 1.4], [4.7, 1.5], [4.7, 1.6], [4.8, 1.8], 
    [4.9, 1.5], [4.8, 1.4], [5. , 1.7], [5.1, 1.6], 
    ])
y1 = np.array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 
    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
    1, 1, 1, 1, ])
# 计算X1数据集中两种数据的凸包
X10 = X1[y1==-1]
X11 = X1[y1==1]
hull10 = ConvexHull(X10)
hull11 = ConvexHull(X11)

# 非线性可分数据集
X2 = np.array([[3. , 1.1], [3.3, 1. ], [3.5, 1. ], [3.6, 1.3], [3.7, 1. ], [3.8, 1.1], 
    [3.9, 1.1], [3.9, 1.2], [3.9, 1.4], [4. , 1. ], [4. , 1.2], [4. , 1.3], [4.1, 1. ], 
    [4.1, 1.3], [4.2, 1.2], [4.2, 1.3], [4.2, 1.5], [4.3, 1.3], [4.4, 1.2], [4.4, 1.3], [4.4, 1.4], 
    [4.5, 1.3], [4.5, 1.5], [4.5, 1.6], [4.5, 1.7], [4.6, 1.3], [4.6, 1.4], [4.6, 1.5], [4.7, 1.2], 
    [4.7, 1.4], [4.7, 1.5], [4.7, 1.6], [4.8, 1.4], [4.8, 1.8], [4.9, 1.5], [4.9, 1.8], [4.9, 2. ], 
    [5. , 1.5], [5. , 1.7], [5. , 1.9], [5. , 2. ], [5.1, 1.5], [5.1, 1.6], [5.1, 1.8], [5.1, 1.9], 
    [5.1, 2. ], [5.1, 2.3], [5.1, 2.4], [5.2, 2. ], [5.2, 2.3], [5.3, 1.9], [5.3, 2.3], [5.4, 2.1], 
    [5.4, 2.3], [5.5, 1.8], [5.5, 2.1], [5.6, 1.4], [5.6, 1.8], [5.6, 2.1], [5.6, 2.2], [5.6, 2.4], 
    [5.7, 2.1], [5.7, 2.3], [5.7, 2.5], [5.8, 1.6], [5.8, 1.8], [5.8, 2.2], [5.9, 2.1], [5.9, 2.3], 
    [6. , 1.8], [6. , 2.5], [6.1, 1.9], [6.1, 2.3], [6.1, 2.5], [6.3, 1.8], [6.4, 2. ], [6.6, 2.1], 
    [6.7, 2. ], [6.7, 2.2], [6.9, 2.3], ])
y2 = np.array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 
    -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, -1, -1, -1, -1, 1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 
    1, 1,  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ])
# 分别计算X2数据集中两种数据的凸包
X20 = X2[y2==-1]
X21 = X2[y2==1]
hull20 = ConvexHull(X20)
hull21 = ConvexHull(X21)

# 以下是绘制代码
# 设置字体大小
plt.rcParams.update({'font.size': 14})
# 创建并排的两个subfigure
fig, axes = plt.subplots(figsize = (6, 3), nrows=1, ncols=2)
plt.subplots_adjust(left=0.001, right=0.999, top=0.999, bottom=0.1, wspace=0.08)

# 在第一个subfigure中绘制 X1 数据集
ax = axes[0]
ax.set(xticks=[], yticks=[]) # 不显示坐标的刻度
ax.scatter(x=X10[:, 0], y=X10[:, 1], alpha=0.8, color='blue', marker= 'x', edgecolor='k') # 绘制 x 点
ax.scatter(x=X11[:, 0], y=X11[:, 1], alpha=0.8, color='red', marker= 'o', edgecolor='k') # 绘制 o 点
# 取出凸包的边界点，构造两个多边形
p10 = Polygon(hull10.points[hull10.vertices])
p11 = Polygon(hull11.points[hull11.vertices])
ax.set_xlabel('两个多边形相交为 {} '.format(p10.intersects(p11)))
# 绘制多边形
ax.plot(*p10.exterior.xy, color='blue')
ax.plot(*p11.exterior.xy, color='red')

# 在第二个subfigure中绘制 X2 数据集
ax = axes[1]
ax.set(xticks=[], yticks=[]) # 不显示坐标的刻度
ax.scatter(x=X20[:, 0], y=X20[:, 1], alpha=0.8, color='blue', marker= 'x', edgecolor='k') # 绘制 x 点
ax.scatter(x=X21[:, 0], y=X21[:, 1], alpha=0.8, color='red', marker= 'o', edgecolor='k') # 绘制 o 点
# 取出凸包的边界点，构造两个多边形
p20 = Polygon(hull20.points[hull20.vertices])
p21 = Polygon(hull21.points[hull21.vertices])
ax.set_xlabel('两个多边形相交为 {} '.format(p20.intersects(p21)))
# 绘制多边形
ax.plot(*p20.exterior.xy, color='blue')
ax.plot(*p21.exterior.xy, color='red')

plt.show()
```

- **线性可分的充要条件**: 各凸包互不相交.



### 口袋算法

- 非线性可分的数据集
- 数据中的噪音
- 口袋算法的思路
- 引入符号函数 Sign.
- 决策边界的评分(Sign & d(X) 复合)![](https://dandelionfs.oss-cn-beijing.aliyuncs.com/ml-pocket algorithm.webp)
- 口袋算法: 在感知机暴力实现的基础上，在固定的迭代次数内不断更正决策边界并打分，从中找到评分最高的作为最终的决策边界：
    - 只有可导的才可以求得区间极值, `sign`不可导, 所以只能通过次数来求最大. 

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import Perceptron
from matplotlib.colors import ListedColormap

# 超参数
epochs = 10 # 固定的迭代次数

# 参数
w, b = np.array([0, 0]), 0 # np.array 相当于定义向量

# 定义 d(x) 函数
def d(x):
    return np.dot(w,x)+b # np.dot 是向量的点积

# 定义 sign 函数
def sign(x):
    return 1 if x >= 0 else -1

# 定义 h(x) 函数
def h(x):
    return sign(d(x))

# 计算决策边界的评分
def clf_score(X, y):
    score = 0
    for xi, yi in zip(X, y):
        score += yi*h(xi)
    return score

# 历史信用卡发行数据，该数据不是线性可分的
X = np.array([[5,2], [3,2], [2,7], [1,4], [6,1], [4,5], [2,5], [3.6,3.8]])
y = np.array([-1, -1, 1, 1, -1, 1, -1, -1])

# 感知机的口袋算法
# 数据比较简单，设定总的循环次数 10 次就够了
best_w, best_b = w, b
best_cs = clf_score(X, y)
for _ in range(epochs):

    # 顺序遍及数据集 X
    for xi, yi in zip(X, y):
        # 如果有分错的
        if yi*d(xi) <= 0:
            # 更新法向量 w 和 b
            w, b = w + yi*xi, b + yi
            # 对新得到的决策边界进行评分
            cs = clf_score(X, y)
            # 如果更好，则进行更新
            if cs > best_cs:
                best_cs = cs
                best_w, best_b = w, b
            break

w, b = best_w, best_b

# 下面是绘制的代码，主要展示暴力实现的结果，看不懂也没有关系
def make_meshgrid(x, y, h=.02):
    """Create a mesh of points to plot in

    Parameters
    ----------
    x: data to base x-axis meshgrid on
    y: data to base y-axis meshgrid on
    h: stepsize for meshgrid, optional

    Returns
    -------
    xx, yy : ndarray
    """
    x_min, x_max = x.min() - 1, x.max() + 1
    y_min, y_max = y.min() - 1, y.max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                         np.arange(y_min, y_max, h))
    return xx, yy

def plot_contours(ax, clf, xx, yy, **params):
    """Plot the decision boundaries for a classifier.

    Parameters
    ----------
    ax: matplotlib axes object
    clf: a classifier
    xx: meshgrid ndarray
    yy: meshgrid ndarray
    params: dictionary of params to pass to contourf, optional
    """
    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)
    out = ax.contourf(xx, yy, Z, **params)
    return out

# 训练 skrlearn 中的感知机，这里是为了借用该感知机的接口，便于绘制决策区域
clf = Perceptron().fit(X, y)
# 根据上面暴力实现得到的 w 和 b 来修改感知机
clf.coef_[0][0], clf.coef_[0][1], clf.intercept_[0] = w[0], w[1], b

# 设置字体大小
plt.rcParams.update({'font.size': 14})
# 设置画布和坐标系
fig, ax = plt.subplots(figsize = (6, 3), nrows=1, ncols=1)
fig.subplots_adjust(left=0.25, right=0.75, top=0.999, bottom=0.001)
ax.set_xticks(()),ax.set_yticks(())

cm = ListedColormap(('blue', 'red'))
markers = ('x', 'o')

# 决定绘制区域的大小
X0, X1 = X[:, 0], X[:, 1]
xx, yy = make_meshgrid(X0, X1)
ax.set_xlim(xx.min(), xx.max())
ax.set_ylim(yy.min(), yy.max())

# 绘制决策区域
plot_contours(ax, clf, xx, yy, cmap=cm, alpha=0.4)

# 绘制决策直线
lx = np.linspace(xx.min(), xx.max())
ly = - w[0] / w[1] * lx  - b / w[1]
ax.plot(lx, ly, 'k-')

# 根据类别不同，绘制不同形状的点
vmin, vmax = min(y), max(y)
for cl, m in zip(np.unique(y), markers):
  ax.scatter(x=X0[y==cl], y=X1[y==cl], c=y[y==cl], alpha=1, vmin = vmin, vmax = vmax, cmap=cm, edgecolors='k', marker = m)

plt.show()
```



之前介绍过 sklearn 库中的乳腺癌数据集，该数据集只包含了两种类别。但它的特征向量是30维向量，一方面不好可视化，另一方面在其上直接运用感知机口袋算法的效果不好，

- **安德森鸢尾花卉**数据集

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import Perceptron
from sklearn import datasets
from matplotlib.colors import ListedColormap

# 超参数
epochs = 2000 # 固定的迭代次数

# 参数
w, b = np.array([0, 0]), 0 # np.array 相当于定义向量

# 定义 d(x) 函数
def d(x):
    return np.dot(w,x)+b # np.dot 是向量的点积

# 定义 sign 函数
def sign(x):
    return 1 if x >= 0 else -1

# 定义 h(x) 函数
def h(x):
    return sign(d(x))

# 计算决策边界的评分
def clf_score(X, y):
    score = 0
    for xi, yi in zip(X, y):
        score += yi*h(xi)
    return score

# 以下是训练代码
# 载入iris数据集
iris = datasets.load_iris()
# 取后面100个数据，并且只取最后两个特征，以及取出对应的类别
sampleNumber = 100
X = iris.data[50:50+sampleNumber, [2,3]]
# iris 数据集的类别是0, 1, 2，为了运用我们实现的感知机算法，这里将后两个类别改为-1, 1
y = np.where(iris.target[50:50+sampleNumber] == 1, -1, 1)

# 感知机的口袋算法
best_w, best_b = w, b
best_cs = clf_score(X, y)
for _ in range(epochs):

    # 顺序遍及数据集 X
    for xi, yi in zip(X, y):
        # 如果有分错的
        if yi*d(xi) <= 0:
            # 更新法向量 w 和 b
            w, b = w + yi*xi, b + yi
            # 对新得到的决策边界进行评分
            cs = clf_score(X, y)
            # 如果更好，则进行更新
            if cs > best_cs:
                best_cs = cs
                best_w, best_b = w, b
            break

w, b = best_w, best_b
# 计算准确率
accuracy = 1 - (sampleNumber - best_cs)/2/sampleNumber

# 下面是绘制的代码，主要展示暴力实现的结果，看不懂也没有关系
def make_meshgrid(x, y, h=.02):
    """Create a mesh of points to plot in

    Parameters
    ----------
    x: data to base x-axis meshgrid on
    y: data to base y-axis meshgrid on
    h: stepsize for meshgrid, optional

    Returns
    -------
    xx, yy : ndarray
    """
    x_min, x_max = x.min() - 1, x.max() + 1
    y_min, y_max = y.min() - 1, y.max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                         np.arange(y_min, y_max, h))
    return xx, yy

def plot_contours(ax, clf, xx, yy, **params):
    """Plot the decision boundaries for a classifier.

    Parameters
    ----------
    ax: matplotlib axes object
    clf: a classifier
    xx: meshgrid ndarray
    yy: meshgrid ndarray
    params: dictionary of params to pass to contourf, optional
    """
    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)
    out = ax.contourf(xx, yy, Z, **params)
    return out

# 训练 skrlearn 中的感知机，这里是为了借用该感知机的接口，便于绘制决策区域
clf = Perceptron().fit(X, y)
# 根据上面暴力实现得到的 w 和 b 来修改感知机
clf.coef_[0][0], clf.coef_[0][1], clf.intercept_[0] = w[0], w[1], b

# 设置字体大小
plt.rcParams.update({'font.size': 14})
# 设置画布和坐标系
fig, ax = plt.subplots(figsize = (6, 3), nrows=1, ncols=1)
fig.subplots_adjust(left=0.25, right=0.75, top=0.999, bottom=0.08)
ax.set_xticks(()),ax.set_yticks(())
ax.set_xlabel(r"epochs：{}，accuracy：{:.2%}".format(epochs, accuracy))


cm = ListedColormap(('blue', 'red'))
markers = ('x', 'o')

# 决定绘制区域的大小
X0, X1 = X[:, 0], X[:, 1]
xx, yy = make_meshgrid(X0, X1)
ax.set_xlim(xx.min(), xx.max())
ax.set_ylim(yy.min(), yy.max())

# 绘制决策区域
plot_contours(ax, clf, xx, yy, cmap=cm, alpha=0.4)

# 绘制决策直线
lx = np.linspace(xx.min(), xx.max())
ly = - w[0] / w[1] * lx  - b / w[1]
ax.plot(lx, ly, 'k-')

# 根据类别不同，绘制不同形状的点
vmin, vmax = min(y), max(y)
for cl, m in zip(np.unique(y), markers):
  ax.scatter(x=X0[y==cl], y=X1[y==cl], c=y[y==cl], alpha=1, vmin = vmin, vmax = vmax, cmap=cm, edgecolors='k', marker = m)

plt.show()
```

### 参数和超参数

- 参数和超参数
    - 	机器学习算法中，可以通过数据集确定的称为参数, 如W和b.
    - 	必须人工调整的称为超参数，比如 epochs 。
- 安德森鸢尾花卉数据集
- 准确率
- 欠拟合
    - 不同的 epochs 对应了不同的准确率，在训练数据集上准确率太低，称为欠拟合：
- 准确率的上限
    - 增大超参数 epochs 就可以提高准确率（也就是解决欠拟合问题），当进一步增大 epochs 准确率没有提高时，就可以确定下最终的 epochs：
    - 无法你想操作

### 学习流程

- 泛化能力最大

    - 才有能力去预测未知的数据集。这种能力在机器学习上称为预测能力，或者称为泛化能力

- 学习流程

    - 把数据集分为三份：训练集(train set)、验证集(test set)和测试集(test set)；

        - 数据保持**随机**

        - 总共有 150 个数据。我们按照 6 : 2 : 2 的比例，将之划分为训练集、验证集和测试集

        - ```python
            #coding:utf-8
            import matplotlib.pyplot as plt
            from matplotlib.colors import ListedColormap
            from sklearn import datasets
            from sklearn.model_selection import train_test_split
            import numpy as np
            
            # 载入iris数据集
            iris = datasets.load_iris()
            # 取后面100个数据，并且只取最后两个特征，以及取出对应的类别
            sampleNumber = 100
            X = iris.data[50:50+sampleNumber, [2,3]]
            # iris 数据集的类别是0, 1, 2，为了运用我们实现的感知机算法，这里将后两个类别改为-1, 1
            y = np.where(iris.target[50:50+sampleNumber] == 1, -1, 1)
            
            # 借助 train_test_split 进行随机分割，按照 6 : 2 : 2 的比例划分为三种数据集
            X_tv, X_test, y_tv, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
            X_train, X_val, y_train, y_val = train_test_split(X_tv, y_tv, test_size=0.25, random_state=42)
            
            # 以下是绘制代码，看不懂没有关系
            plt.rcParams.update({'font.size': 18}) # 设置字体大小
            # 创建并设置排的两个subfigure
            fig, axes = plt.subplots(figsize = (9, 3), nrows=1, ncols=3)
            plt.subplots_adjust(left=0.001, right=0.999, top=0.999, bottom=0.1, wspace=0.04)
            
            # 在两个并排的subfigure中绘制训练集和测试集
            cmaps = (ListedColormap(('blue', 'red')), ListedColormap(('dodgerblue', 'bisque')), ListedColormap(('forestgreen', 'peru')))
            markers, xlabels  = ('x', 'o'), ('训练集', '验证集', '测试集')
            Xs, ys = (X_train, X_val, X_test), (y_train, y_val, y_test)
            for ax, xlabel, cm, X, y in zip(axes.flat, xlabels, cmaps, Xs, ys):
                ax.set(xticks=[], yticks=[])
                ax.set_xlabel(xlabel)
            
                vmin, vmax = min(y), max(y)
                for cl, m in zip(np.unique(y), markers):
                    ax.scatter(x=X[y==cl, 0], y=X[y==cl, 1], c=y[y==cl], alpha=1, vmin = vmin, vmax = vmax, cmap=cm, edgecolors='k', marker = m)
            
            plt.show()
            ```

    - 在训练集上学习参数，比如和（好比日常学习）；

    - 在验证集上调整超参数，比如 epochs（好比模拟考试）；

    - 重复（2）（3）步，直到参数和超参数都比较满意；

    - 最后在测试集上检验最终的学习效果（好比高考）。

    

- 鸢尾花数据集的划分

```python
#coding:utf-8
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap
from sklearn import datasets
from sklearn.model_selection import train_test_split
import numpy as np

# 载入iris数据集
iris = datasets.load_iris()
# 取后面100个数据，并且只取最后两个特征，以及取出对应的类别
sampleNumber = 100
X = iris.data[50:50+sampleNumber, [2,3]]
# iris 数据集的类别是0, 1, 2，为了运用我们实现的感知机算法，这里将后两个类别改为-1, 1
y = np.where(iris.target[50:50+sampleNumber] == 1, -1, 1)

# 借助 train_test_split 进行随机分割，按照 6 : 2 : 2 的比例划分为三种数据集
X_tv, X_test, y_tv, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
X_train, X_val, y_train, y_val = train_test_split(X_tv, y_tv, test_size=0.25, random_state=42)

# 以下是绘制代码，看不懂没有关系
plt.rcParams.update({'font.size': 18}) # 设置字体大小
# 创建并设置排的两个subfigure
fig, axes = plt.subplots(figsize = (9, 3), nrows=1, ncols=3)
plt.subplots_adjust(left=0.001, right=0.999, top=0.999, bottom=0.1, wspace=0.04)

# 在两个并排的subfigure中绘制训练集和测试集
cmaps = (ListedColormap(('blue', 'red')), ListedColormap(('dodgerblue', 'bisque')), ListedColormap(('forestgreen', 'peru')))
markers, xlabels  = ('x', 'o'), ('训练集', '验证集', '测试集')
Xs, ys = (X_train, X_val, X_test), (y_train, y_val, y_test)
for ax, xlabel, cm, X, y in zip(axes.flat, xlabels, cmaps, Xs, ys):
    ax.set(xticks=[], yticks=[])
    ax.set_xlabel(xlabel)

    vmin, vmax = min(y), max(y)
    for cl, m in zip(np.unique(y), markers):
        ax.scatter(x=X[y==cl, 0], y=X[y==cl, 1], c=y[y==cl], alpha=1, vmin = vmin, vmax = vmax, cmap=cm, edgecolors='k', marker = m)

plt.show()
```

- 训练和验证
- 过拟合: 这种对训练集贴合得非常好，但是泛化能力下降
    - 通过验证集的准确率来调整超参数，可以尽可能避免过拟合
- 最终测试: 只能用测试集来给出最终的泛化能力测试结果

### 交叉验证

- k 折交叉验证 (K-fold Cross Validation) : 替换单纯使用验证集来调整超参数
    - 过程
        - 将数据集分为两部分，分别是训练集和测试集；
        - 将要调整的超参给定一个值，比如说 epochs = 100；
        - 将训练集随机平均的分为 k 份，依次选择其中的一份作为验证集，剩余的仍然作为训练集，或称为某一折。因为可以有 k 份不同的验证集，所以总共有 k 折；
        - 在某一折上，通过训练集算出参数，然后在验证集上算出准确率；
        - 在不同的折上，重复（3）（4）步，得到 k 个准确率，将这些准确率的平均数作为最终的结果，并记录下来。
        - 然后，不断调整超参数，比如说 epochs = 200；不断重复（3）（4）（5）和（6），直到找到平均准确率最高的超参数；
        - 最后，使用找到的超参数，在整个训练集上进行训练，这样就可以使用更多的数据用于训练。
- k 折交叉验证的实现

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn import datasets
from sklearn.model_selection import KFold
from matplotlib.colors import ListedColormap

# 超参数
epochs = 100 # 固定的迭代次数

# 参数
w, b = np.array([0, 0]), 0 # np.array 相当于定义向量

# 定义 d(x) 函数
def d(x):
    return np.dot(w,x)+b # np.dot 是向量的点积

# 定义 sign 函数
def sign(x):
    return 1 if x >= 0 else -1

# 定义 h(x) 函数
def h(x):
    return sign(d(x))

# 计算决策边界的评分
def clf_score(X, y):
    score = 0
    for xi, yi in zip(X, y):
        score += yi*h(xi)
    return score

# 感知机的口袋算法
def PLA_pocket(X, y):
    global epochs, w, b

    w, b = np.array([0, 0]), 0 # np.array 相当于定义向量
    best_w, best_b = w, b
    best_cs = clf_score(X, y)
    for _ in range(epochs):

        # 顺序遍及数据集 X
        for xi, yi in zip(X, y):
            # 如果有分错的
            if yi*d(xi) <= 0:
                # 更新法向量 lw 和 lb
                w, b = w + yi*xi, b + yi
                # 对新得到的决策边界进行评分
                cs = clf_score(X, y)
                # 如果更好，则进行更新
                if cs > best_cs:
                    best_cs = cs
                    best_w, best_b = w, b
                break

    w, b = best_w, best_b

# 以下是训练代码
# 载入iris数据集
iris = datasets.load_iris()
# 取后面100个数据，并且只取最后两个特征，以及取出对应的类别
sampleNumber = 100
X = iris.data[50:50+sampleNumber, [2,3]]
# iris 数据集的类别是0, 1, 2，为了运用我们实现的感知机算法，这里将后两个类别改为-1, 1
y = np.where(iris.target[50:50+sampleNumber] == 1, -1, 1)

# 借助 train_test_split 进行随机分割，按照 8 : 2  的比例划分为训练验证集、测试集
rs = 42
X_tv, X_test, y_tv, y_test = train_test_split(X, y, test_size=0.2, random_state=rs)
print(r'总共有 {} 个数据，其中训练验证集中有 {} 个数据，测试集中有 {} 个数据。'.format(len(X), len(X_tv), len(X_test)))

# 在 X_tv 上进行 k 折交叉验证
k = 10
kf = KFold(n_splits=k, random_state=rs)
val_accuracy = 0
for idx, (train, val) in zip(range(k), kf.split(X_tv)):
    X_train, y_train, X_val, y_val = X_tv[train], y_tv[train], X_tv[val], y_tv[val]
    PLA_pocket(X_train, y_train)
    split_train_accuracy = 1 - (len(X_train) - clf_score(X_train, y_train))/2/len(X_train)
    split_val_accuracy = 1 - (len(X_val) - clf_score(X_val, y_val))/2/len(X_val)
    print(r'第 {} 折，训练集准确率 {:.2%} ，验证集准确率 {:.2%}'.format(idx + 1, split_train_accuracy, split_val_accuracy))
    val_accuracy += split_val_accuracy
print(r'epochs = {}，验证集准确率的平均值为 {:.2%}。'.format(epochs, val_accuracy / k))
```

- 调整超参数

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn import datasets
from sklearn.model_selection import KFold
from matplotlib.colors import ListedColormap

# 超参数
epochs = 100 # 固定的迭代次数

# 参数
w, b = np.array([0, 0]), 0 # np.array 相当于定义向量

# 定义 d(x) 函数
def d(x):
    return np.dot(w,x)+b # np.dot 是向量的点积

# 定义 sign 函数
def sign(x):
    return 1 if x >= 0 else -1

# 定义 h(x) 函数
def h(x):
    return sign(d(x))

# 计算决策边界的评分
def clf_score(X, y):
    score = 0
    for xi, yi in zip(X, y):
        score += yi*h(xi)
    return score

# 感知机的口袋算法
def PLA_pocket(X, y):
    global epochs, w, b

    w, b = np.array([0, 0]), 0 # np.array 相当于定义向量
    best_w, best_b = w, b
    best_cs = clf_score(X, y)
    for _ in range(epochs):

        # 顺序遍及数据集 X
        for xi, yi in zip(X, y):
            # 如果有分错的
            if yi*d(xi) <= 0:
                # 更新法向量 lw 和 lb
                w, b = w + yi*xi, b + yi
                # 对新得到的决策边界进行评分
                cs = clf_score(X, y)
                # 如果更好，则进行更新
                if cs > best_cs:
                    best_cs = cs
                    best_w, best_b = w, b
                break

    w, b = best_w, best_b

# 以下是训练代码
# 载入iris数据集
iris = datasets.load_iris()
# 取后面100个数据，并且只取最后两个特征，以及取出对应的类别
sampleNumber = 100
X = iris.data[50:50+sampleNumber, [2,3]]
# iris 数据集的类别是0, 1, 2，为了运用我们实现的感知机算法，这里将后两个类别改为-1, 1
y = np.where(iris.target[50:50+sampleNumber] == 1, -1, 1)

# 借助 train_test_split 进行随机分割，按照 8 : 2  的比例划分为训练验证集、测试集
rs = 42
X_tv, X_test, y_tv, y_test = train_test_split(X, y, test_size=0.2, random_state=rs)
print(r'总共有 {} 个数据，其中训练验证集中有 {} 个数据，测试集中有 {} 个数据。'.format(len(X), len(X_tv), len(X_test)))

# 组合两个超参数，计算各种组合得到的验证集准确率的平均值
k = 10
for epochs in  range(100, 500, 100):
    kf = KFold(n_splits=k, random_state=rs)
    val_accuracy = 0
    for idx, (train, val) in zip(range(k), kf.split(X_tv)):
        X_train, y_train, X_val, y_val = X_tv[train], y_tv[train], X_tv[val], y_tv[val]
        PLA_pocket(X_train, y_train)
        val_accuracy += 1 - (len(X_val) - clf_score(X_val, y_val))/2/len(X_val)
    print(r'epochs = {}，k={}，验证集准确率的平均值为 {:.2%}。'.format(epochs, k, val_accuracy / k))
```

- 最终测试
- 不同的 k 值: 关于 k 值的选择是一个有争论性的话题，一般建议选择 k = 10。

### Logistic regression

- 线性分类和线性回归
- 最小二乘法是无偏估计，并且是最佳线性无偏估计，因此可以处理噪音问题
- 口袋算法实现的线性二分类（即感知机）没有办法处理噪音问题，因此需要引入另外一种线性二分类 逻辑回归



![](https://z3.ax1x.com/2021/06/28/RNt0kn.png)

<div id="j1">[1]. https://www.matongxue.com/</div>